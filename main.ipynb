{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamadHBaydoun/COMP9444/blob/MohamadBranch/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MohamadHBaydoun/COMP9444.git"
      ],
      "metadata": {
        "id": "UcB2qg_PdJjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF4j-Au2cGQi"
      },
      "outputs": [],
      "source": [
        "# 0. Import packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojWzYY-VcGQi"
      },
      "outputs": [],
      "source": [
        "# 1. Create model\n",
        "\n",
        "\n",
        "# USE RESIDUAL NEURAL NETWORKS AND FCN'S WITH 1X1 CONVOLUTIONS AND UPSAMPLING OPERATIONS\n",
        "import torch\n",
        "\n",
        "class CustomFCN(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super(CustomFCN, self).__init__()\n",
        "\n",
        "        # Downsampling (Encoder)\n",
        "        self.enc1a = self.conv_chain(in_channels, 3, 3, 8, 1, 1)\n",
        "        self.enc1 = self.conv_chain(8, 3, 3, 8, 1, 1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.enc2a = self.conv_chain(8, 3, 3, 16, 1, 1)\n",
        "        self.enc2 = self.conv_chain(16, 3, 3, 16, 1, 1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "        self.enc3a = self.conv_chain(16, 3, 3, 32, 1, 1)\n",
        "        self.enc3 = self.conv_chain(32, 3, 3, 32, 1, 1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
        "\n",
        "       # Upsampling (Decoder)\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec1 = self.conv_chain(32, 3, 3, 16, 1, 1)\n",
        "\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec2 = self.conv_chain(16, 3, 3, 8, 1, 1)\n",
        "\n",
        "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec3 = nn.Conv2d(in_channels=8, out_channels=out_channels, kernel_size=1, padding=0, stride=1)\n",
        "\n",
        "    def conv_chain(self, Din, L, M, D, S, P):\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(in_channels=Din, out_channels=D, kernel_size=(L, M), padding=P, stride=S),\n",
        "          nn.BatchNorm2d(D),\n",
        "          nn.ReLU(inplace=True)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1 = self.pool1(self.enc1a(x))\n",
        "        x2 = self.pool2(self.enc2a(x1))\n",
        "        x3 = self.pool3(self.enc3a(x2))\n",
        "        #x1 = self.iterative_forward(x, self.pool1, self.enc1a, self.enc1)\n",
        "        #x2 = self.iterative_forward(x1, self.pool2, self.enc2a, self.enc2)\n",
        "        #x3 = self.iterative_forward(x2, self.pool3, self.enc3a, self.enc3)\n",
        "\n",
        "        # Decoder\n",
        "        y = self.up1(x3)\n",
        "        y = self.dec1(y)\n",
        "        y = y + x2\n",
        "\n",
        "        y = self.up2(y)\n",
        "        y = self.dec2(y)\n",
        "        y = y + x1\n",
        "\n",
        "        y = self.up3(y)\n",
        "        y = self.dec3(y)\n",
        "\n",
        "        return torch.sigmoid(y)\n",
        "    def iterative_forward(self, x, poolFunc, encFuncA, encFunc):\n",
        "        # Encoder\n",
        "        xNew = encFuncA(x)\n",
        "        for i in range(7):\n",
        "          xNew = encFunc(xNew)\n",
        "        return poolFunc(xNew)\n",
        "\n",
        "# Create model instance\n",
        "model = CustomFCN()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf78kx0AcGQj"
      },
      "outputs": [],
      "source": [
        "# 2. Prepare data\n",
        "IMAGE_PATH = \"./COMP9444/top_200_images/images\"\n",
        "LABEL_PATH = \"./COMP9444/top_200_images/\"\n",
        "\n",
        "def load_image(path, isLabel=False):\n",
        "    \"\"\"Load an RGB image and convert to a tensor\"\"\"\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((480, 640)),  # Resize images\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "\n",
        "    ])\n",
        "    if isLabel:\n",
        "      transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((480, 640)),  # Resize images\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "    ])\n",
        "    return transform(img)  # Apply transform\n",
        "\n",
        "class QuakeCityDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_list):\n",
        "        self.file_list = file_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.file_list[idx]\n",
        "        img = load_image(os.path.join(IMAGE_PATH, filename))\n",
        "        # component = load_annotation(\"component\", filename)\n",
        "        crack = load_image(os.path.join(LABEL_PATH, \"crack\", filename), isLabel=True)\n",
        "        # spall = load_annotation(\"spall\", filename)\n",
        "        # rebar = load_annotation(\"rebar\", filename)\n",
        "        # ds = load_annotation(\"ds\", filename)\n",
        "        # depth = load_annotation(\"depth\", filename)\n",
        "        label = crack\n",
        "        return img, label\n",
        "\n",
        "all_files = sorted(os.listdir(IMAGE_PATH))\n",
        "split_idx = int(0.5*len(all_files))\n",
        "train_files = all_files[split_idx:]\n",
        "test_files = all_files[:split_idx]\n",
        "\n",
        "train_dataset = QuakeCityDataset(train_files)\n",
        "test_dataset = QuakeCityDataset(test_files)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "img_test_batch, label_test_batch = next(iter(test_loader))\n",
        "print(\"Test image batch shape:\", img_test_batch.shape)\n",
        "print(\"Test label batch shape:\", label_test_batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97t759BVcGQk"
      },
      "outputs": [],
      "source": [
        "# 2.5 Visualise data\n",
        "def visualize_sample(image, label):\n",
        "    \"\"\"Display the image and its 6 label masks.\"\"\"\n",
        "    label_names = [\"Component\", \"Crack\", \"Spall\", \"Rebar\", \"Damage State\", \"Depth\"]\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    # Show the original image\n",
        "    axes[0].imshow(image.permute(1, 2, 0))  # Convert (C, H, W) -> (H, W, C)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "    # Show the label mask\n",
        "    axes[1].imshow(label.squeeze(), cmap='gray')  # Visualize label\n",
        "    axes[1].set_title(label_names[1])\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "img_batch, label_batch = next(iter(train_loader))\n",
        "visualize_sample(img_batch[0], label_batch[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCOuHxzIcGQk"
      },
      "outputs": [],
      "source": [
        "# 3. Choose optimizer\n",
        "\n",
        "criterion = nn.BCELoss()  # binary classification loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-qhNyL9cGQl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses = []\n",
        "epochs = 500\n",
        "\n",
        "for epoch in range(1, epochs):\n",
        "    for batch_id, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Save and print loss\n",
        "        losses.append(loss.item())\n",
        "        print('Epoch%3d: zero_grad(): loss=%7.4f output_mean=%7.4f target_mean=%7.4f' %\n",
        "              (epoch, loss.item(), output.mean().item(), target.mean().item()))\n",
        "\n",
        "\n",
        "        # Compare results\n",
        "        output_image = output[-1].cpu().detach().numpy()\n",
        "        target_image = target[-1].cpu().detach().numpy()\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "        # Show the original image\n",
        "        axes[0].imshow(output_image.squeeze(), cmap='gray')  # Convert (C, H, W) -> (H, W, C)\n",
        "        axes[0].set_title(f\"Epoch {epoch} - Output Image\")\n",
        "        axes[0].axis(\"off\")\n",
        "        # Show the label mask\n",
        "        axes[1].imshow(target_image.squeeze(), cmap='gray')  # Visualize label\n",
        "        axes[1].set_title(f\"Target Image\")\n",
        "        axes[1].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "                # Plot live loss curve\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(losses, label='Training Loss')\n",
        "        plt.xlabel('Batch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Live Loss Curve')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchmetrics\n"
      ],
      "metadata": {
        "id": "c9pQML8MGjon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_score(outputs, targets, threshold=0.5):\n",
        "    outputs = (outputs > threshold).float()\n",
        "    intersection = (outputs * targets).sum()\n",
        "    union = outputs.sum() + targets.sum() - intersection\n",
        "    iou = intersection / union\n",
        "    return iou.item()\n",
        "\n",
        "def dice_coefficient(outputs, targets, threshold=0.5):\n",
        "    outputs = (outputs > threshold).float()\n",
        "    intersection = (outputs * targets).sum()\n",
        "    dice = (2 * intersection) / (outputs.sum() + targets.sum())\n",
        "    return dice.item()\n",
        "\n",
        "model.eval()\n",
        "total_iou, total_dice = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "        #images, masks = images.cuda(), masks.cuda()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "\n",
        "        total_iou += iou_score(outputs, masks)\n",
        "        total_dice += dice_coefficient(outputs, masks)\n",
        "\n",
        "# Average metrics for the epoch\n",
        "avg_iou = total_iou / len(test_loader)\n",
        "avg_dice = total_dice / len(test_loader)\n",
        "print(f'Validation - IoU: {avg_iou:.4f}, Dice: {avg_dice:.4f}')"
      ],
      "metadata": {
        "id": "6guTrEwX2HPE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}